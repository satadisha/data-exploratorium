{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19e16b3c",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center; gap: 2px;\">\n",
    "  \n",
    "  <div style=\"text-align: left; padding: 0;\">\n",
    "   <h2 style=\"font-size: 1.8em; margin-bottom: 0;\"><b>Non Linearity in Regression...</b></h2>\n",
    "   <br>\n",
    "   <h3 style=\" font-size: 1.2em;margin-bottom: 0;\">Alternatives to Linear Regression</h3>\n",
    "   <h3 style=\"font-size: 1.2em; margin-bottom: 0; color: blue;\"><i>Dr. Satadisha Saha Bhowmick</i></h3>\n",
    "  </div>\n",
    "\n",
    "  <div style=\"margin-right: 5px; padding: 0;\">\n",
    "    <img src=\"images/intro-pic.png\" align=\"right\" alt=\"intro-pic\" style=\"width: 70%;\">\n",
    "    <!-- TEXT NEXT TO IMAGE -->\n",
    "      <div style=\"font-size: 0.5em;\">\n",
    "        <p>Woman teaching geometry, from a fourteenth-century edition of Euclid’s geometry book.</p>\n",
    "      </div>\n",
    "  </div>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e6ac71",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.colors import ListedColormap\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "from ipywidgets import interact\n",
    "import sklearn.metrics as metrics\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "bac_data = pd.read_csv(\"BLOODALC.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9289f626",
   "metadata": {},
   "source": [
    "### Week 2: Learning Outcomes\n",
    "Moving beyond Simple Linear Regression\n",
    "\n",
    "<div style=\"display: flex; gap: 2px;\">\n",
    "\n",
    "  <div style=\"flex: 1;\">\n",
    "  <ul>\n",
    "    <li class=\"fragment\">Adjust for nonlinearity in regression using squared and polynomial terms.</li>\n",
    "    <li class=\"fragment\">Adjust for nonconstant variance or outlying values using weighted least squares.</li>\n",
    "  </ul>\n",
    "\n",
    "  \n",
    "  </div>\n",
    "\n",
    "  <div style=\"flex: 1;\">\n",
    "  <ul>\n",
    "    <li class=\"fragment\">Use regularization methods like ridge or LASSO for large $p$, small $n$ problems.</li>\n",
    "    <li class=\"fragment\">Variable Selection using Ridge or LASSO.</li>\n",
    "    <li class=\"fragment\">Use smoothers (splines in particular) to detect patterns in data.</li>\n",
    "  </ul>\n",
    "  </div>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b55dd1",
   "metadata": {},
   "source": [
    "### Non Linearity\n",
    "Often the relationship between the response variable $Y$ and the independent variable $X$ is non-linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cf5724",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "X = np.random.normal(0,1,size=(100,1))\n",
    "Y = 2*X + np.exp(X) + np.random.normal(1,1,size=(100,1))\n",
    "\n",
    "plt.scatter(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd825fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X,Y)\n",
    "\n",
    "plt.scatter(X,Y)\n",
    "plt.plot(np.arange(-3,2.5,0.1),reg.predict(np.arange(-3,2.5,0.1).reshape(-1,1)),color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2db4ed",
   "metadata": {},
   "source": [
    "### Squared and Polynomial Terms\n",
    "\n",
    "What happens if you see a curved pattern in your residuals?\n",
    "\n",
    "We can use squared terms (or even higher order!) in linear regression by simply adding a squared term to the design matrix.\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\begin{bmatrix}\n",
    "1 & x_{11} & x^2_{11}\\\\\n",
    "1 & x_{21} & x^2_{21}\\\\\n",
    "\\vdots & \\vdots & \\vdots\\\\\n",
    "1 & x_{n1} & x^2_{n1}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "\\beta_0\\\\\n",
    "\\beta_1\\\\\n",
    "\\beta_2\n",
    "\\end{bmatrix} &= \\begin{bmatrix}\n",
    "y_1\\\\\n",
    "y_2\\\\\n",
    "\\vdots\\\\\n",
    "y_n\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}$$\n",
    "\n",
    "Because the squared terms are captured in the design matrix, we can still consider this to be “linear in the parameters”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88ee199",
   "metadata": {},
   "source": [
    "### Some Practical Notes\n",
    "\n",
    "- To implement, just add a new column to your dataframe.\n",
    "- To avoid multicollinearity, center your feature terms.\n",
    "- You can also add higher order terms, $x^3$, $x^4$, etc.\n",
    "- If you have a higher order term, it is good practice to include all lower order terms leading up to it.\n",
    "    - A model with $x^2$ must include $x$.\n",
    "    - A model with $x^3$ must include $x^2$ and $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411a9bc2",
   "metadata": {},
   "source": [
    "### Interaction Terms\n",
    "\n",
    "You can also construct an interaction term.\n",
    "- An interaction term is appropriate when a dependent variable (outcome) changes, depending on the variation of one or more other predictors simultaneously.\n",
    "- In a regression equation, an interaction effect is represented as the product of two or more predictors.\n",
    "$$\n",
    "y_i = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_{12}x_1x_2\n",
    "$$\n",
    "- We can use interactions terms in linear regression by simply adding the term to the design matrix.\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\begin{bmatrix}\n",
    "1 & x_{11} & x_{12} & x_{11}x_{12}\\\\\n",
    "1 & x_{21} & x_{22} & x_{21}x_{22}\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots\\\\\n",
    "1 & x_{n1} & x_{n2} & x_{n1}x_{n2}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "\\beta_0\\\\\n",
    "\\beta_1\\\\\n",
    "\\beta_2\\\\\n",
    "\\beta_{12}\n",
    "\\end{bmatrix} &= \\begin{bmatrix}\n",
    "y_1\\\\\n",
    "y_2\\\\\n",
    "\\vdots\\\\\n",
    "y_n\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
