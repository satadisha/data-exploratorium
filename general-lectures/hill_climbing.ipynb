{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ff14029",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display: flex; align-items: center;\">\n",
    "  \n",
    "  <div style=\"text-align: left;\">\n",
    "   <h2 style=\"font-size: 1.8em; margin-bottom: 0;\"><b>Going downhill with purpose</b></h2>\n",
    "   <br>\n",
    "   <h3 style=\" font-size: 1.2em;margin-bottom: 0;\">An overview of Gradient Descent</h3>\n",
    "   <h3 style=\"font-size: 1.2em; margin-bottom: 0; color: blue;\"><i>Dr. Satadisha Saha Bhowmick</i></h3>\n",
    "  </div>\n",
    "\n",
    "  <div style=\"margin-right: 10px;\"> \n",
    "    <img src=\"media/images/dsi-logo-600.png\" align=\"right\" alt=\"UC-DSI\" scale=\"0.7;\">\n",
    "  </div>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2185f30f",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<!-- ### Learning Loop -->\n",
    "\n",
    "<div style=\"display: flex; align-items: center;gap: 5px;\">\n",
    "  <div style=\"flex: 1;\">\n",
    "    <h3>About Me</h3>\n",
    "  <h4>Satadisha Saha Bhowmick, Ph.D</h4>\n",
    "\n",
    "  <div class=\"fragment\"  style=\"font-size: 14px;\">\n",
    "    <h4>Affiliation</h4>\n",
    "    <ul>\n",
    "      <li>Postdoctoral Teaching Fellow <br> Data Science Institute, University of Chicago</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"fragment\"  style=\"font-size: 14px;\">\n",
    "    <h4>Courses I teach</h4>\n",
    "    <ul>\n",
    "      <li>Introduction to Data Science</li>\n",
    "      <li>Mathematical Methods for Data Science</li>\n",
    "      <li>Ethics, Fairness, Responsibility, and Privacy in Data Science</li>\n",
    "      <li>Object Oriented Programming with Java</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"fragment\"  style=\"font-size: 14px;\">\n",
    "    <h4>Research Interest</h4>\n",
    "    <ul>\n",
    "      <li>Information Extraction</li>\n",
    "      <li>Short Text Mining</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "  \n",
    "  </div>\n",
    "  <div style=\"flex: 1;\">\n",
    "    <img src=\"media/images/satadisha-photo.png\" alt=\"Self\" scale=\"0.3\">\n",
    "  </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "202afaa3",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.colors import ListedColormap\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e55b55",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Teaching Demonstration\n",
    "Course Module from CS 231 Machine Learning Fundamentals\n",
    "\n",
    "<div style=\"display: flex; gap: 2px;\">\n",
    "\n",
    "  <div style=\"flex: 1;\">\n",
    "  <h4>Today's Learning Outcomes</h4>\n",
    "  <ul>\n",
    "    <li class=\"fragment\"> How do we make models that learn well from data?</li>\n",
    "    <li class=\"fragment\"> First principles to build intuition on model optimization</li>\n",
    "    <li class=\"fragment\">Gradient Descent</li>\n",
    "    <li class=\"fragment\">Impact of Learning Rate</li>\n",
    "    <li class=\"fragment\">Gradient Descent in practice</li>\n",
    "  </ul>\n",
    "\n",
    "  \n",
    "  </div>\n",
    "\n",
    "  <div style=\"flex: 1;\">\n",
    "  <h4>Prerequisites</h4>\n",
    "  <ul>\n",
    "    <li class=\"fragment\"> Vector Calculus</li>\n",
    "    <li class=\"fragment\"> Linear Algebra</li>\n",
    "  </ul>\n",
    "  </div>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8370d5bd",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Teaching Demonstration\n",
    "More to Follow\n",
    "\n",
    "  <ul>\n",
    "    <li>Learning Rate Schedules</li>\n",
    "    <li>Strategies for Learning Rate adjustment</li>\n",
    "      <ul>\n",
    "        <li>AdaGrad</li>\n",
    "        <li>Newton's Method</li>\n",
    "      </ul>\n",
    "    <li>Algorithmic variants for Gradient Descent</li>\n",
    "  </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b4c560",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<!-- ### Learning Loop -->\n",
    "\n",
    "<div style=\"display: flex; align-items: center;gap: 20px;\">\n",
    "  <div style=\"flex: 3;\">\n",
    "    <h3>Learning Loop</h3>\n",
    "    <p>Machine Learning systems within a supervised setup typically involve a <b>model of choice</b> and a <b>loss function</b>.</p>\n",
    "\n",
    "  <ul>\n",
    "    <li class=\"fragment\">The model is a (mathematical) function of its parameters.</li>\n",
    "    <li class=\"fragment\">The loss function measures how far an estimated value of an example is from its true value as a function of the model parameters.</li>\n",
    "    <ul>\n",
    "      <li class=\"fragment\">Common loss functions: Squared Loss, Log Loss, Cross-Entropy Loss (for multiclass classification)</li>\n",
    "    </ul>\n",
    "  </ul>\n",
    "\n",
    "  \n",
    "<span class=\"fragment\"> In some problem settings, we have a general *objective* function instead of a loss, like the *likelihood* of a certain output or label given the data, that we might want to maximize.</span>\n",
    "\n",
    "<span class=\"fragment\"> The purpose of training in supervised learning is to obtain the parameter values for the best possible model. \n",
    "<span style=\"color:blue;\">The *best* model involves parameters that can lead to ***optimizing*** the training loss.</span></span>\n",
    "  \n",
    "  </div>\n",
    "  <div style=\"flex: 1;\">\n",
    "    <img src=\"media/images/learning-loop.png\" alt=\"The Learning Loop\" scale=\"1\">\n",
    "  </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cf4744",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model Optimization\n",
    "\n",
    "<span class=\"fragment\"> The optimal training loss is when the loss function assumes its lowest value. Optimization is <span style=\"color:blue;\"><b>minimizing the loss</b></span>!</span>\n",
    "\n",
    "<span class=\"fragment\"> In most cases, it is impossible or difficult to find the minimum of the loss function analytically; instead, we turn to numerical methods from the field of <i>continuous optimization</i>.</span>\n",
    "\n",
    "<span class=\"fragment\"> In this lecture, we will mostly talk about <b>unconstrained optimization</b>.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b45703",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Setting the Scene\n",
    "\n",
    "We begin by setting some key terminologies.\n",
    "\n",
    "<span class=\"fragment\"> Supervised learning involves training data consisting of many examples. Let a single datapoint or example be denoted by: $(x,y) \\text{ where } x \\in {\\cal R}^{n}$.\n",
    "</span>\n",
    "\n",
    "<span class=\"fragment\"> Depending on the problem $y$ could be:</span>\n",
    "<ul>\n",
    "  <li class=\"fragment\"> Numeric: $y \\in {\\cal R}$ for regression problems</li>\n",
    "  <li class=\"fragment\">Categorical: for classification problems</li>\n",
    "</ul>\n",
    "\n",
    "<span class=\"fragment\">The model output $\\hat{y}$ is a function of its features. For a regression problem: $\\hat{y} = f_{\\theta}(x)$, where $f_{\\theta}: {\\cal R}^{n} \\rightarrow {\\cal R}$ and  $ \\theta \\in {\\cal R}^{n} $</span>\n",
    "\n",
    "<span class=\"fragment\">A training set of $m$ examples, $m_{train}: {(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}) \\dots (x^{(m)}, y^{(m)})}$</span>\n",
    "\n",
    "<span class=\"fragment\">Loss is calculated on individual examples. For a regression problem, we will typically use squared loss : $\\mathcal{L}(\\theta) = (y-\\hat{y})^2$</span>\n",
    "\n",
    "<span class=\"fragment\">To learn from the entire training set, we aggregate the loss from each example into a **Cost function** : $$\\mathcal{J}(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} (y^{(i)} - \\hat{y}^{(i)})^2$$</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b76cbb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Loss Function\n",
    "\n",
    "Our loss function $f_{\\theta}$ should be:\n",
    "<ul>\n",
    "    <li class=\"fragment\"> Continuous : well defined and limit exists, no breaks!</li>\n",
    "    <li class=\"fragment\"> Differentiable : derivative exists at every point of its domain.</li>\n",
    "    <li class=\"fragment\"> Convex : any line segment connecting two points of the graph of $f_{\\theta}$ lies on or above the graph</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2f2b75",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Univariate functions\n",
    "| Convex Function | Non-convex Function |\n",
    "|:-------:|:-------:|\n",
    "| <img src=\"media/images/parabola.png\" width=\"300\"> | <img src=\"media/images/non-convex.png\" width=\"300\"> |\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<span class=\"fragment\">\n",
    "<h4 style=\"color: blue; font-weight: bold; font-style: italic;\">Over to You &#9997;</h4>\n",
    "Can you identify the minimum and maximum points of each of these functions? Is there only one per curve?</br>\n",
    "</span>\n",
    "\n",
    "<span class=\"fragment\">\n",
    "<p style=\"color: blue;\">Convex functions have one <b>global minima</b>!</p>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9be115",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Multivariate functions\n",
    "| Convex Function | Non-convex Function |\n",
    "|:-------:|:-------:|\n",
    "| <img src=\"media/images/convex-multi.png\" width=\"800\"> | <img src=\"media/images/non-convex-multi.png\" width=\"900\"> |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0949f49e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to detect optimal points of a function?\n",
    "\n",
    "Let's start with the univariate case.\n",
    "\n",
    "<span class=\"fragment\">\n",
    "  <p><b>At a local optima:</b></p>\n",
    "  <ol>\n",
    "    <li>The tangent line is horizontal.\n",
    "        <ul>\n",
    "        <li>First-order derivative (gradient) is 0.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Function curvature is indicative.\n",
    "        <ul>\n",
    "        <li>Second-order derivative is positive at a minima and negative at a maxima.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "  </ol>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe5581b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How to detect optimal points of a function?\n",
    "\n",
    "<div style=\"display: flex; align-items: center; gap: 5px;\">\n",
    "\n",
    "  <div class=\"fragment\"; style=\"flex: 2;\">\n",
    "  <p>For $f(x) = x^4 + 7x^3 + 5x^2 - 17x + 3$</p>\n",
    "  <ol>\n",
    "    <li> $f^{'}(x) = 4x^3 + 21x^2 + 10x - 17$\n",
    "        <ul>\n",
    "        <li>finding the optimal points becomes a root finding problem</li>\n",
    "        <li>optimal points at  -4.48, -1.43 and 0.66 are real of the equation $f^{'}(x)=0$</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li> $f^{''}(x) = 12x^2 + 42x + 10$\n",
    "        <ul>\n",
    "        <li>plugging in the roots of $f^{'}(x)$ we get two local minima at -4.48 and 0.66  as well as a local maxima at -1.43</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "  </ol>\n",
    "  </div>\n",
    "  <div class=\"fragment\"; style=\"flex: 1;\">\n",
    "    <img src=\"media/gif/local_optima_animation.gif\" alt=\"Optimal Points of a Function\" scale=\"0.6;\" style=\"width: 90%;\">\n",
    "    <img src=\"media/images/roots.png\" alt=\"Optimal Points of a Function\" scale=\"0.6;\" style=\"width: 90%;\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<!-- SINGLE-COLUMN SECTION -->\n",
    "<div class=\"fragment\" style=\"margin-top: 20px;\">\n",
    "  <p>Around a local minima, $f(x)$ is decreasing if $x$ is less than the minima and increasing if it is greater. These behaviours hold uniformly for all $x$ values for a convex function with a single global minima.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1945caa1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How to detect optimal points of a multivariate function?\n",
    "\n",
    "For $f(x): {\\cal R}^{n} \\rightarrow {\\cal R}$, we still have the same derivative tests for a local optima $x^*$.\n",
    "\n",
    "<span class=\"fragment\" style=\"font-size: 14px;\">\n",
    "  <ol>\n",
    "    <li>Gradient is a $n$ dimensional vector of first-order partial derivatives.\n",
    "      $\\nabla f(x) = \\begin{pmatrix}\n",
    "      \\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial x_n}\n",
    "      \\end{pmatrix} = 0$\n",
    "    </li>\n",
    "    <li>Second-order partial derivatives are organized in a $n \\times n$ matrix called the Hessian:\n",
    "      $$\n",
    "      H(f)(\\mathbf{x}) = \\nabla^{2} f(x)\n",
    "      \\begin{bmatrix}\n",
    "      \\frac{\\partial^2 f}{\\partial x_1^2} \n",
    "      & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} \n",
    "      & \\cdots\n",
    "      & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_n}\n",
    "      \\\\[0.5em]\n",
    "      \\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} \n",
    "      & \\frac{\\partial^2 f}{\\partial x_2^2} \n",
    "      & \\cdots\n",
    "      & \\frac{\\partial^2 f}{\\partial x_2 \\partial x_n}\n",
    "      \\\\[0.5em]\n",
    "      \\vdots & \\vdots & \\ddots & \\vdots\n",
    "      \\\\[0.5em]\n",
    "      \\frac{\\partial^2 f}{\\partial x_n \\partial x_1} \n",
    "      & \\frac{\\partial^2 f}{\\partial x_n \\partial x_2} \n",
    "      & \\cdots \n",
    "      & \\frac{\\partial^2 f}{\\partial x_n^2}\n",
    "      \\end{bmatrix}\n",
    "      $$\n",
    "      Assuming that the matrix is symmetric and invertible at a critical point,\n",
    "        <ul>\n",
    "        <li>At a local minima, $H(x^*)$ is <b>positive definite</b>. All eigenvalues must be positive ($\\forall v; v^{T}Hv > 0$).</li>\n",
    "        <li>At a local maxima, $H(x^*)$ is <b>negative definite</b>. All eigenvalues must be negative ($\\forall v; v^{T}Hv < 0$).</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "  </ol>\n",
    "\n",
    "  You can find more about the <a href=\"https://en.wikipedia.org/wiki/Second_partial_derivative_test\" target=\"_blank\">second partial derivative test</a> as well as the simplified determinant test for the bivariate case.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe9e33a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Big Idea\n",
    "\n",
    "<div style=\"display: flex; align-items: center; gap: 5px;\">\n",
    "\n",
    "  <div class=\"fragment\"; style=\"flex: 1;\">\n",
    "    <p>Loss surfaces for most ML algorithms involve complex, high-dimensional functions. We also do not know much about the form they take.\n",
    "    Analytically deriving closed form optimal solutions here becomes infeasible.</p>\n",
    "    <p><b>Iterative Approach</b>: For a <b>convex loss function</b>, start from any given point and \"<i>walk down</i>\" the curve in small steps to reach the deepest point.</p>\n",
    "    <span class=\"fragment\">\n",
    "    <p><b>For a multivariate $f(\\theta): {\\cal R}^{n} \\rightarrow {\\cal R}$, how should we proceed for this?</b></p>\n",
    "    <ul>\n",
    "      <li>Look at Taylor Approximations!</li>\n",
    "      <li>Knowing local behaviour gives global information.</li>\n",
    "    </ul>\n",
    "    </span>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"fragment\"; style=\"flex: 1;\">\n",
    "    <img src=\"media/gif/taylor.gif\" alt=\"Taylor approximations\" scale=\"0.45;\" style=\"width: 90%;\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<div class=\"fragment\">\n",
    "$$\n",
    "f(\\theta + h) \\approx f(\\theta) + f^{'}(\\theta)h + \\frac{f^{''}(\\theta)}{2!}h^2 + \\frac{f^{'''}(\\theta)}{3!}h^3 + \\dots\n",
    "$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e996381",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient Descent from first principles\n",
    "\n",
    "Starting from point $\\vec{\\theta}$, we wish to take a small step $\\vec{h}$, such that  $f(\\vec{\\theta}+\\vec{h})<f(\\vec{\\theta})$.\n",
    "\n",
    "If $\\vec{h} \\in {\\cal R}^{n}$ is small enough, i.e. $\\lVert \\vec{h} \\rVert \\approx 0$, we can use Taylor expansion to obtain a locally linear approximation of $f$ around $\\vec{\\theta} = (\\theta_{1}, \\theta_{2} \\dots \\theta_{n})$.\n",
    "\n",
    "$$\n",
    "f(\\vec{\\theta}+\\vec{h}) \\approx f(\\vec{\\theta}) + \\nabla f(\\vec{\\theta})^{T} \\vec{h}\n",
    "$$\n",
    "\n",
    "This assumes that the function $f$ is differentiable around $\\vec{\\theta}$ and $\\nabla f$ is non-zero. If we choose $\\vec{h} = - \\eta \\nabla f$ for a small positive factor $\\eta$, then as per the approximation\n",
    "\n",
    "$$\\begin{aligned}\n",
    "&& f(\\vec{\\theta} - \\eta \\nabla f) \\approx f(\\vec{\\theta}) - \\eta \\nabla f(\\vec{\\theta})^{T} \\nabla f(\\vec{\\theta}) \\\\\n",
    "&& f(\\vec{\\theta} - \\eta \\nabla f) \\approx f(\\vec{\\theta}) - \\eta \\lVert \\nabla f(\\vec{\\theta}) \\rVert^{2}_{2}\n",
    "\\end{aligned}$$\n",
    "\n",
    "As we know the norm of a vector to be positive, subtracting $\\eta \\lVert \\nabla f(\\vec{\\theta}) \\rVert^{2}_{2}$ from $f(\\vec{\\theta})$ would result in a decrease of the value of $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd845e59",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient Descent\n",
    "\n",
    "<div class=\"fragment\">\n",
    "\n",
    "Intuitively, gradient $\\nabla f$ is known as the direction of steepest increase of $f$. Hence taking a step proportional to $-\\nabla f$ will be in the direction of the steepest reduction for $f$ and take us to its minima. \n",
    "\n",
    "The magnitude of the step is determined by the (positive) factor $\\eta$, also known as the *learning rate* or *step-size*.\n",
    "\n",
    "This is the crux of *Gradient Descent*.\n",
    "</div>\n",
    "\n",
    "<div class=\"fragment\" style=\"\n",
    "    border: 4px solid #3b82f6;\n",
    "    background: #eef6ff;\n",
    "    padding: 10px 15px;\n",
    "    border-radius: 6px;\n",
    "    margin: 10px auto;\n",
    "    width: 90%;\n",
    "    box-sizing: border-box;\">\n",
    "\n",
    "  <b>Definition.</b>  \n",
    "  $\\color{blue}{\\textbf{Gradient Descent}}$ is an iterative algorithm to minimize a convex loss function. Starting from an initial value, the parameter vector $\\vec{\\theta}$ is updated in each iteration, as per the following rule, until a convergence criterion is reached:\n",
    "  $$\n",
    "  \\vec{\\theta} \\leftarrow \\vec{\\theta} - \\eta \\nabla f\n",
    "  $$\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1a28e0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Gradient Descent Pseudocode\n",
    "\n",
    "<div style=\"\n",
    "    border: 2px solid #a2aab9ff;\n",
    "    background: #eef3ff;\n",
    "    padding: 14px;\n",
    "\tfont-size: 15px;\n",
    "    border-radius: 6px;\n",
    "    font-family: 'Courier New', monospace;\n",
    "    width: 90%;\n",
    "    margin: 15px auto;\n",
    "    box-sizing: border-box;\">\n",
    "\n",
    "<pre style=\"\n",
    "    font-size: 1.5em !important;        /* ←  MAKE TEXT BIGGER */\n",
    "    line-height: 1.4em;\n",
    "\">\n",
    "\n",
    "function GRADIENT_DESCENT(J, v, η):\n",
    "    θ⁰ ← v\n",
    "    while not converged:\n",
    "        grad ← ∇J(θ⁽ᵗ⁾)\n",
    "\t∀i: θᵢ⁽ᵗ⁺¹⁾ ← θᵢ⁽ᵗ⁾ − η * gradᵢ\n",
    "    return θ\n",
    "\n",
    "</pre>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57dc940",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Gradient Descent: Example 1\n",
    "<div style=\"display: flex; align-items: center; gap: 5px;\">\n",
    "\n",
    "  <div class=\"fragment\"; style=\"flex: 1;\">\n",
    "  <p>For the convex function $f(\\theta_{1}, \\theta_{2}) = \\theta_{1}^2+\\theta_{2}^2$</p>\n",
    "\n",
    "  <span class=\"fragment\">\n",
    "  $$\n",
    "  \\begin{aligned}\n",
    "    \\frac{\\partial f}{\\partial \\theta_{1}} = 2\\theta_{1}; \\frac{\\partial f}{\\partial \\theta_{2}} = 2\\theta_{2} \\\\\n",
    "  \\end{aligned}\n",
    "  $$\n",
    "  </span>\n",
    "\n",
    "  <span class=\"fragment\">\n",
    "  Starting at $\\theta^{(0)} = (0.8, 0.8)$ with a step size of $\\eta=0.1$, here we run the Gradient Descent algorithm for 20 steps.\n",
    "\n",
    "  The value of $f$ at $\\theta^{(20)}$ after 20 iterations is $1.7014 \\times 10^{-4}$, which is quite close to the global minimum of 0.\n",
    "  </span>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"fragment\"; style=\"flex: 1;\">\n",
    "    <img src=\"media/gif/gd_fixed_0.10.gif\" alt=\"Gradient Descent Example\" scale=\"0.55;\" style=\"width: 90%;\">\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9566fe27",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Gradient Descent over Cost Functions\n",
    "\n",
    "**Linearity of Gradient** implies that $\\nabla (f_{1}+f_{2}) = \\nabla f_{1}+\\nabla f_{2}$. This property has practical importance.\n",
    "\n",
    "Implies that, the gradient of the entire cost function $\\mathcal{J}$ can be found by taking the sum (average) of the gradient of the loss $f$ on individual examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d35db0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convergence\n",
    "\n",
    "In an iterative algorithm like Gradient Descent, convergence can be defined by a few possible stopping criteria and some pre-defined tolerance value $\\tau > 0$.\n",
    "\n",
    "<span class=\"fragment\">1. Maximum number of iterations: <i>use this regardless</i></span>\n",
    "\n",
    "<span class=\"fragment\">2. $\\lVert\\mathcal{J}(\\theta^{t+1})-\\mathcal{J}(\\theta^{t})\\rVert < \\tau$</span>\n",
    "\n",
    "<span class=\"fragment\">3. $\\lVert\\theta^{t+1}-\\theta^{t}\\rVert < \\tau$</span>\n",
    "\n",
    "<span class=\"fragment\">4. $\\lVert \\nabla f(\\theta^{t+1}) \\rVert < \\tau$</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378f8e40",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display: flex; gap: 30px; align-items: flex-start; min-height: 400px;\">\n",
    "\n",
    "  <!-- LEFT COLUMN -->\n",
    "  <div style=\"flex: 1;\">\n",
    "\n",
    "### Choosing a good step-size\n",
    "\n",
    "<span class=\"fragment\">The parameter learning rate $\\eta$ determines the magnitude of the step taken in the direction of negative gradient.</span>\n",
    "\n",
    "<span class=\"fragment\">\n",
    "\n",
    "For example, consider gradient descent on a function $f(x) = (x-5)^2$ starting at $x^{(0)}=10$, with learning rate $\\eta=1$. The minima is at $x=5$. Is this a good learning rate?\n",
    "</span>\n",
    "\n",
    "<span class=\"fragment\">\n",
    "<h4 style=\"color: blue; font-weight: bold; font-style: italic;\">Over to You &#9997;</h4>\n",
    "\n",
    "What values do $x$ assume by the end of the first and second iterations of gradient descent: $x^{(1)}$ and $x^{(2)}$?<br>\n",
    "What does that tell us about the learning rate?\n",
    "</span>\n",
    "\n",
    "  </div>\n",
    "\n",
    "  <!-- RIGHT COLUMN -->\n",
    "  <div style=\"flex: 1; display: flex; flex-direction: column; align-items: center;\">\n",
    "\n",
    "  <!-- IMAGE FIRST -->\n",
    "  <div class=\"fragment\">\n",
    "      <img src=\"media/gif/gd_oscillation.gif\" alt=\"Gradient Descent Oscillation\" style=\"width: 90%;\">\n",
    "  </div>\n",
    "\n",
    "  <!-- TEXT ON NEXT CLICK -->\n",
    "  <div class=\"fragment\" style=\"margin-top: 20px; text-align: center;\">\n",
    "      Learning rate ideally should not be too large, else Gradient Descent may never converge!\n",
    "  </div>\n",
    "\n",
    "  </div>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b783e37",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Choosing a good step-size\n",
    "\n",
    "<div class=\"fragment\">\n",
    "  Learning rate is important for convergence. But how do we choose it?\n",
    "</div>\n",
    "\n",
    "<div class=\"fragment\">\n",
    "\n",
    "  Consider the convex function $f(x) = \\frac{1}{2}x^2$ with a global minima at $x=0$.\n",
    "  Start with $\\eta^{(0)} = 0.1$, $x^{(0)}=1$, and use a decreasing sequence of learning rates.  \n",
    "  Do we reach the minima?\n",
    "</div>\n",
    "\n",
    "<div class=\"fragment\">\n",
    "  <ol>\n",
    "    <li>$\\eta^{0}=0.1*1,\\ \\eta^{1}=0.1*\\tfrac12,\\ \\eta^{2}=0.1*\\tfrac14,\\dots, \\eta^{t}=0.1*\\tfrac1{2^t}$</li>\n",
    "    <li>$\\eta^{0}=0.1*1,\\ \\eta^{1}=0.1*\\tfrac12,\\ \\eta^{2}=0.1*\\tfrac13,\\dots, \\eta^{t}=0.1*\\tfrac1{t+1}$</li>\n",
    "  </ol>\n",
    "</div>\n",
    "\n",
    "<div class=\"fragment\">\n",
    "\n",
    "With $\\nabla f(x) = x$, we have the following Gradient Descent updates,\n",
    "$$\\small \\begin{aligned}\n",
    "x^1 = x^0 - \\eta^{0}x^0 = (1-\\eta^{0})x^0 \\\\\n",
    "x^2 = (1-\\eta^{1})x^1 = (1-\\eta^{1})(1-\\eta^{0})x^0 \\\\\n",
    "x^t = (1-\\eta^{t-1})\\dots(1-\\eta^{1})(1-\\eta^{0})x^0 = x^{(0)} \\prod_{k=0}^{t-1} (1-\\eta^{k})\n",
    "\\end{aligned}$$\n",
    "As $t \\rightarrow \\infty$, $x^{\\infty} = x^{(0)} \\prod_{k=0}^{\\infty} (1-\\eta^{k})$\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054d101a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Choosing a good step-size\n",
    "\n",
    "<div class=\"fragment\">\n",
    "\n",
    "Convergence to $x=0$ as $t \\rightarrow \\infty$, depends on $\\prod_{k=0}^{\\infty} (1-\\eta^{k}) \\rightarrow 0$.<br>\n",
    "For $0 \\leq \\eta^{k} < 1$, we know from the <a href= \"https://archive.org/details/theoryandapplica031692mbp\" target=\"_blank\"> criteria of convergence for infinite products</a>:\n",
    "$$\\small \\begin{aligned}\n",
    "\\text{if }\\sum_{k=0}^{\\infty}\\eta^{k}={\\infty}  \\text{ ; } \\prod_{k=0}^{\\infty} (1-\\eta^{k})=0\\\\\n",
    "\\text{if } \\sum_{k=0}^{\\infty}\\eta^{k}<{\\infty} \\text{ ; } \\prod_{k=0}^{\\infty} (1-\\eta^{k})=\\text{C; a finite positive number }\n",
    "\\end{aligned}$$\n",
    "</div>\n",
    "\n",
    "<div class=\"fragment\">\n",
    "\n",
    "<table style=\"border-collapse: collapse; width: 80%; margin: auto;\">\n",
    "  <tr>\n",
    "    <th style=\"border: 1px solid black; text-align: center;\">Case 1</th>\n",
    "    <th style=\"border: 1px solid black; text-align: center;\">Case 2</th>\n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "    $\\eta^{0}=0.1*1,\\ \\eta^{1}=0.1*\\tfrac12,\\ \\eta^{2}=0.1*\\tfrac14,\\dots, \\eta^{t}=0.1*\\tfrac1{2^t}$\n",
    "    </td>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "    $\\eta^{0}=0.1*1,\\ \\eta^{1}=0.1*\\tfrac12,\\ \\eta^{2}=0.1*\\tfrac13,\\dots, \\eta^{t}=0.1*\\tfrac1{t+1}$\n",
    "    </td>\n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "      $\\sum_{k=0}^{\\infty}\\eta^{k} = \\sum_{k=0}^{\\infty}\\frac{0.1}{2^k}$\n",
    "    </td>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "      $\\sum_{k=0}^{\\infty}\\eta^{k} = \\sum_{k=0}^{\\infty}\\frac{0.1}{k+1}$\n",
    "    </td>\n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "      $\\sum_{k=0}^{\\infty}\\eta^{k} = 0.2$\n",
    "    </td>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "      $\\sum_{k=0}^{\\infty}\\eta^{k} = \\infty$\n",
    "    </td>\n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "      As $t \\rightarrow \\infty$, $x^{\\infty} = x^{(0)} C \\neq 0$\n",
    "    </td>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "      As $t \\rightarrow \\infty$, $x^{\\infty} = x^{(0)} 0 = 0$\n",
    "    </td>\n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "      finite movement; freezes above minimum\n",
    "    </td>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "      infinite movement; eventually converges to minimum\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9c61a1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Choosing a good step-size\n",
    "\n",
    "<div class=\"fragment\">\n",
    "  Could be tuned like a hyperparameter! Remember:\n",
    "  <ol>\n",
    "    <li>Cannot be too high when gradients are large.</li>\n",
    "    <li>Cannot be too low when on a shallow curve — Gradient Descent slows down as it gets closer to the minima.</li>\n",
    "    <li>Ideally, should go down as we run more iterations and get closer to the minima.</li>\n",
    "  </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ccbba0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Algorithmic Variants\n",
    "\n",
    "<span class=\"fragment\">\n",
    "<b>Batch Gradient Descent</b>\n",
    "\n",
    "- Regular Gradient Descent involves computing the full cost function – loss function for all training examples – to adjust a parameter value in a single iterative step. Computationally infeasible for large datasets!\n",
    "</span>\n",
    "\n",
    "<span class=\"fragment\">\n",
    "<b>Stochastic Gradient Descent</b>\n",
    "\n",
    "- Every step of gradient descent is taken based of the loss computed on one example. \n",
    "- Extremely fast updates. But calculations based on single example can introduce a lot of variance (random updates hence stochastic)! It also never fully converges but hovers asymptotically close to the local minima.\n",
    "- Updates are noisy but the randomness helps us get out of local minima or other bad regions. Less prone to overfitting.\n",
    "</span>\n",
    "\n",
    "<span class=\"fragment\">\n",
    "<b>Mini Batch Gradient Descent</b>\n",
    "\n",
    "- Randomly split training data into mini-batches, compute a gradient descent step according to a mini-batch. Most commonly used in practice.\n",
    "- Parallelizable on GPUs.\n",
    "- A happy medium. Smoother convergence but also computationally less expensive.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ab7e1b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What next?\n",
    "\n",
    "Follow-up lecture:\n",
    "\n",
    "  <ul>\n",
    "    <li>Learning Rate Schedules</li>\n",
    "      <ul>\n",
    "        <li>Can we decreasing sequence of learning rates?</li>\n",
    "      </ul>\n",
    "    <li>Strategies for Learning Rate adjustment</li>\n",
    "      <ul>\n",
    "        <li>AdaGrad: asymmetrical learning rate along different dimensions</li>\n",
    "        <li>Newton's Method: use curvature information from second order derivative instead of fixed learning rate</li>\n",
    "      </ul>\n",
    "  </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8343b807",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Adagrad\n",
    "\n",
    "<div class=\"fragment\">\n",
    "Should all features be assigned the same learning rate?\n",
    "\n",
    "- Even after feature scaling, different features have different rates of influence on the learning problem, and consequently on the model and the cost function.\n",
    "</div>\n",
    "\n",
    "<div class=\"fragment\">\n",
    "Solution:\n",
    "\n",
    "- Keep a history of feature updates\n",
    "- Decay the learning rate of a feature over time in proportion to the update history.\n",
    "    - Large gradients: Dense features or high rate of change; small learning rate.\n",
    "    - Small gradients: Sparse features or low rate of change; large learning rate.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6af47b",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Adagrad Pseudocode\n",
    "\n",
    "<div style=\"\n",
    "    border: 2px solid #a2aab9ff;\n",
    "    background: #eef3ff;\n",
    "    padding: 14px;\n",
    "    border-radius: 6px;\n",
    "    font-family: 'Courier New', monospace;\n",
    "    width: 90%;\n",
    "    margin: 15px auto;\n",
    "    box-sizing: border-box;\">\n",
    "\n",
    "<pre>\n",
    "function ADAGRAD(J, v, η):\n",
    "    ∀i: θ⁽⁰⁾ ← v; grad_hᵢ⁽⁰⁾ ← 0\n",
    "    while not converged:\n",
    "        ∀i: grad_hᵢ⁽ᵗ⁾ ← grad_hᵢ⁽ᵗ⁻¹⁾+ ∇Jᵢ(θᵢ⁽ᵗ⁾)²\n",
    "        ∀i: θᵢ⁽ᵗ⁺¹⁾ ← θᵢ⁽ᵗ⁾ − η/√(grad_hᵢ⁽ᵗ⁾ + ε) * ∇Jᵢ(θᵢ⁽ᵗ⁾)\n",
    "    return θ\n",
    "</pre>\n",
    "convergence is defined by $\\lVert\\theta^{t+1}-\\theta^{t}\\rVert_2 < \\tau$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559d07ac",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<div style=\"display: flex; gap: 30px; align-items: flex-start; min-height: 400px;\">\n",
    "\n",
    "  <!-- LEFT COLUMN -->\n",
    "  <div style=\"flex: 1;\">\n",
    "\n",
    "  ### Newton's Method\n",
    "\n",
    "  <div class=\"fragment\">\n",
    "\n",
    "  Gradient Descent assumes a linear approximation of a function and moves down it's slope in small steps to iteratively reach the minima. Alternatively, one can approach optimization using a quadratic approximation of the loss function.\n",
    "  </div>\n",
    "\n",
    "  <div class=\"fragment\">\n",
    "\n",
    "  If $\\vec{h} \\in {\\cal R}^{n}$ is small enough, i.e. $\\lVert \\vec{h} \\rVert \\approx 0$, Taylor expansion can be used to obtain a quadratic approximation of $f$ around $\\vec{\\theta} = (\\theta_{1}, \\theta_{2} \\dots \\theta_{n})$ to capture curvature, not just slope.\n",
    "  $$\n",
    "  f(\\vec{\\theta}+\\vec{h}) \\approx f(\\vec{\\theta}) + \\nabla f(\\vec{\\theta})^{T} \\vec{h} + \\frac{1}{2} \\vec{h}^T H(\\vec{\\theta})\\vec{h}\n",
    "  $$\n",
    "  </div>\n",
    "\n",
    "  </div>\n",
    "\n",
    "  <!-- RIGHT COLUMN -->\n",
    "  <div style=\"flex: 1; display: flex; flex-direction: column; align-items: center;\">\n",
    "\n",
    "  <!-- IMAGE FIRST -->\n",
    "  <div class=\"fragment\">\n",
    "      <img src=\"media/images/taylor_2.png\" alt=\"Taylor Expansion\" style=\"width: 90%;\">\n",
    "  </div>\n",
    "  \n",
    "  </div>\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"fragment\">\n",
    "  This is equivalent to locally fitting a parabola around the point of interest $\\vec{\\theta}$. \n",
    "  Here we assume that the function is <b>twice differentiable</b>. The iterative search here follows by taking the next step to the minima of this convex parabola.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263555a5",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Newton's Method\n",
    "\n",
    "<div class=\"fragment\">\n",
    "\n",
    "Differentiating the equation for $f(\\vec{\\theta}+\\vec{h})$ w.r.t. $\\vec{h}$ we have,\n",
    "$$\n",
    "\\nabla_{\\vec{h}} [f(\\vec{\\theta}) + \\nabla f(\\vec{\\theta})^{T} \\vec{h} + \\frac{1}{2} \\vec{h}^T H(\\vec{\\theta})\\vec{h}] = \\nabla f(\\vec{\\theta}) + H(\\vec{\\theta})\\vec{h}\n",
    "$$\n",
    "</div>\n",
    "\n",
    "<div class=\"fragment\">\n",
    "\n",
    "Setting the derivative to 0 we can derive,\n",
    "$$\\begin{aligned}\n",
    "&& \\nabla f(\\vec{\\theta}) + H(\\vec{\\theta})\\vec{h} = 0 \\\\\n",
    "&& \\vec{h} = -  H^{-1}(\\vec{\\theta})\\nabla f(\\vec{\\theta})\n",
    "\\end{aligned}$$\n",
    "\n",
    "This is the update that is made in each iteration of the Newton's method until convergence. Note that we no longer rely on a scalar learning rate.\n",
    "$$\n",
    "\\vec{\\theta} \\leftarrow \\vec{\\theta} -  H^{-1}(\\vec{\\theta})\\nabla f(\\vec{\\theta})\n",
    "$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea2a9ac",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Newton's Method: Example 2\n",
    "<div style=\"display: flex; align-items: center; gap: 5px;\">\n",
    "\n",
    "  <div class=\"fragment\"; style=\"flex: 1;\">\n",
    "\n",
    "  <p>For the convex function $f(\\theta_{1}, \\theta_{2}) = \\theta_{1}^2+\\theta_{2}^2$</p>\n",
    "\n",
    "<!--\n",
    "  <span class=\"fragment\">\n",
    "  $$\n",
    "  \\begin{aligned}\n",
    "    \\frac{\\partial f}{\\partial \\theta_{1}} = 2\\theta_{1}; \\frac{\\partial f}{\\partial \\theta_{2}} = 2\\theta_{2} \\\\\n",
    "  \\end{aligned}\n",
    "  $$\n",
    "  </span>\n",
    "-->\n",
    "\n",
    "  <span class=\"fragment\">\n",
    "  Starting at $\\theta^{(0)} = (0.8, 0.8)$, here we run Newton's Method.\n",
    "\n",
    "  After just 5 iterations, value of $f$ at $\\theta^{(5)}$ is $1.7014 \\times 10^{-4}$. This is quite close to the global minimum of 0.\n",
    "\n",
    "  It took Gradient Descent 20 iterations to get to this value.\n",
    "  </span>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"fragment\"; style=\"flex: 2;\">\n",
    "    <img src=\"media/gif/newton.gif\" alt=\"Gradient Descent\" scale=\"0.55;\" style=\"width: 90%;\">\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ea37a6",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Newton's Method\n",
    "\n",
    "<span class=\"fragment\">\n",
    "<p> Pros: </p>\n",
    "<ul>\n",
    "    <li>Newton's method ensures much faster convergence than Gradient Descent.</li>\n",
    "    <li>Automatically adapts the step size based on the curvature of the function (Hessian), removing the need for hyperparameter tuning of learning rate.</li>\n",
    "</ul>\n",
    "</span>\n",
    "<span class=\"fragment\">\n",
    "<p> Cons: </p>\n",
    "<ul>\n",
    "    <li>Computing both the Gradient and the Hessian and its inverse involves high computational costs for very high dimensional function</li>\n",
    "    <li>Starting from a bad initial guess, may cause the function to diverge or oscillate over the optima.</li>\n",
    "</ul>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0deef4",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Where do we start?\n",
    "\n",
    "<div class=\"fragment\">\n",
    "<p>Gradient Descent requires us to initialize the parameter search with an initial guess. What constitutes a good guess?<p>\n",
    "</div>\n",
    "\n",
    "<div class=\"fragment\">\n",
    "\n",
    "**Random Initialization**\n",
    "- Small random values.\n",
    "- Things are better with a convex objective function.\n",
    "    - Unique global minima, so guaranteed to converge.\n",
    "- For non-convex function, we can get trapped in a local minima depending on initialization.\n",
    "    - Start the search from different positions, and see where each search ends up.\n",
    "    - Choose the best out of all minimizers.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa1f74a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Algorithmic Variants\n",
    "\n",
    "<span class=\"fragment\">\n",
    "<b>Batch Gradient Descent</b>\n",
    "\n",
    "- Regular Gradient Descent involves computing the full cost function – loss function for all training examples – to adjust a parameter value in a single iterative step. Computationally infeasible for large datasets!\n",
    "</span>\n",
    "\n",
    "<span class=\"fragment\">\n",
    "<b>Stochastic Gradient Descent</b>\n",
    "\n",
    "- Every step of gradient descent is taken based of the loss computed on one example. \n",
    "- Extremely fast updates. But calculations based on single example can introduce a lot of variance (random updates hence stochastic)! It also never fully converges but hovers asymptotically close to the local minima.\n",
    "- Updates are noisy but the randomness helps us get out of local minima or other bad regions. Less prone to overfitting.\n",
    "</span>\n",
    "\n",
    "<span class=\"fragment\">\n",
    "<b>Mini Batch Gradient Descent</b>\n",
    "\n",
    "- Randomly split training data into mini-batches, compute a gradient descent step according to a mini-batch. Most commonly used in practice.\n",
    "- Parallelizable on GPUs.\n",
    "- A happy medium. Smoother convergence but also computationally less expensive.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956bbfff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient Descent in Practice\n",
    "\n",
    "<div style=\"display: flex; align-items: center; gap: 5px;\">\n",
    "\n",
    "  <div class=\"fragment\"; style=\"flex: 1;\">\n",
    "\n",
    "  <div>\n",
    "  <b>Problem</b>: Binary Classification of Tumor Cell as Benign or Malignant\n",
    "  </div>\n",
    "\n",
    "  <div>\n",
    "  <b>Dataset</b>: Wisconsin Diagnostic Breast Cancer (WDBC) dataset; <br>\n",
    "           569 cell samples; 8 real valued features\n",
    "  </div>\n",
    "\n",
    "  <div>\n",
    "  <b>Train/Test Split</b>: 80/20\n",
    "  </div>\n",
    "\n",
    "  <div>\n",
    "  <b>Model of Choice</b>: Logistic Regression\n",
    "  </div>\n",
    "\n",
    "  <div>\n",
    "  <b>Loss Function</b>: Logistic Loss\n",
    "  </div>\n",
    "\n",
    "  </div>\n",
    "\n",
    "\n",
    "\n",
    "  <div class=\"fragment\"; style=\"flex: 2;\">\n",
    "    <img src=\"media/images/model_comparison.png\" alt=\"Gradient Descent\" scale=\"0.40;\" style=\"width: 90%;\">\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8fbdc2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Gradient Descent in Practice\n",
    "\n",
    "<div class=\"fragment\">\n",
    "\n",
    "<table style=\"border-collapse: collapse; width: 80%; margin: auto;\">\n",
    "  <tr>\n",
    "    <th style=\"border: 1px solid black; text-align: center;\">Optimization Method</th>\n",
    "    <th style=\"border: 1px solid black; text-align: center;\">Train Accuracy</th>\n",
    "    <th style=\"border: 1px solid black; text-align: center;\">Test Accuracy</th>\n",
    "    <th style=\"border: 1px solid black; text-align: center;\">Test F1 Score</th>\n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "    Gradient Descent\n",
    "    </td>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "    0.9824175824175824\n",
    "    </td>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "    <b>0.9912280701754386</b>\n",
    "    </td>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "    <b>0.993006993006993</b>\n",
    "    </td>\n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "    Stochastic Gradient Descent\n",
    "    </td>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "    0.9758241758241758\n",
    "    </td>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "    0.9736842105263158\n",
    "    </td>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "    0.9790209790209791\n",
    "    </td>\n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "    Mini-Batch Gradient Descent\n",
    "    </td>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "    0.9868131868131869\n",
    "    </td>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "    0.9824561403508771\n",
    "    </td>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "    0.9859154929577465\n",
    "    </td>\n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "    AdaGrad\n",
    "    </td>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "    0.9868131868131869\n",
    "    </td>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "    0.9824561403508771\n",
    "    </td>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "    0.9859154929577465\n",
    "    </td>\n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "    Newton's Method\n",
    "    </td>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "    <b>0.989010989010989</b>\n",
    "    </td>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "    0.9649122807017544, \n",
    "    </td>\n",
    "    <td style=\"border: 1px solid black; text-align: center;\">\n",
    "    0.9714285714285714\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa355195",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Thank You!\n",
    "\n",
    "<div style=\"display: flex; align-items: center; gap: 5px;\">\n",
    "\n",
    "  <div style=\"flex: 1;\">\n",
    "  <h3>Remember:</h3>\n",
    "  <h4>Things going downhill, not so bad!</h4><br><br>\n",
    "  <h4>The gradients are the friends you made along the way!</h4>\n",
    "\n",
    "  </div>\n",
    "\n",
    "\n",
    "\n",
    "  <div style=\"flex: 2;\">\n",
    "    <img src=\"media/images/gd-cartoon.png\" alt=\"Gradient Descent\" scale=\"0.40;\" style=\"width: 90%;\">\n",
    "  </div>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
