{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e52268dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display: flex; align-items: center;\">\n",
    "  \n",
    "  <div style=\"text-align: left;\">\n",
    "   <h2 style=\"font-size: 1.8em; margin-bottom: 0;\"><b>Branching out decisions in a tree</b></h2>\n",
    "   <br>\n",
    "   <h3 style=\" font-size: 1.2em;margin-bottom: 0;\">Decision Trees and Ensemble Learning</h3>\n",
    "   <h3 style=\"font-size: 1.2em; margin-bottom: 0; color: blue;\"><i>Dr. Satadisha Saha Bhowmick</i></h3>\n",
    "  </div>\n",
    "\n",
    "  <div style=\"margin-right: 10px;\"> \n",
    "    <img src=\"media/images/dsi-logo-600.png\" align=\"right\" alt=\"UC-DSI\" scale=\"0.7;\">\n",
    "  </div>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aadf503",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<!-- ### Learning Loop -->\n",
    "\n",
    "<div style=\"display: flex; align-items: center;gap: 5px;\">\n",
    "  <div style=\"flex: 1;\">\n",
    "    <h3>About Me</h3>\n",
    "  <h4>Satadisha Saha Bhowmick, Ph.D</h4>\n",
    "\n",
    "  <div class=\"fragment\"  style=\"font-size: 14px;\">\n",
    "    <h4>Affiliation</h4>\n",
    "    <ul>\n",
    "      <li>Postdoctoral Teaching Fellow <br> Data Science Institute, University of Chicago</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"fragment\"  style=\"font-size: 14px;\">\n",
    "    <h4>Courses I teach</h4>\n",
    "    <ul>\n",
    "      <li>Introduction to Data Science</li>\n",
    "      <li>Mathematical Methods for Data Science</li>\n",
    "      <li>Ethics, Fairness, Responsibility, and Privacy in Data Science</li>\n",
    "      <li>Object Oriented Programming with Java</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"fragment\"  style=\"font-size: 14px;\">\n",
    "    <h4>Research Interest</h4>\n",
    "    <ul>\n",
    "      <li>Information Extraction</li>\n",
    "      <li>Short Text Mining</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "  \n",
    "  </div>\n",
    "  <div style=\"flex: 1;\">\n",
    "    <img src=\"media/images/satadisha-photo.png\" alt=\"Self\" scale=\"0.3\">\n",
    "  </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd8b9e3a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.colors import ListedColormap\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "from ipywidgets import interact\n",
    "df = pd.read_csv(\"data/data_for_tree_Oct22.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa4d239",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Today's Learning Outcomes\n",
    "Course Module from DATA 119 Introduction to Data Science II\n",
    "\n",
    "<div style=\"display: flex; gap: 2px;\">\n",
    "\n",
    "  <div style=\"flex: 1;\">\n",
    "\n",
    "  <ul>\n",
    "    <li class=\"fragment\"> General understanding of Tree Models</li>\n",
    "    <li class=\"fragment\"> Data driven decision making with trees</li>\n",
    "    <li class=\"fragment\">Impurity functions to build decision boundaries for tree models.</li>\n",
    "  </ul>\n",
    "\n",
    "  \n",
    "  </div>\n",
    "\n",
    "  <div style=\"flex: 1;\">\n",
    "  <ul>\n",
    "    <li class=\"fragment\">Using an ensemble of tree-based learners</li> \n",
    "    <li class=\"fragment\"> Bagging</li>\n",
    "    <li class=\"fragment\"> Boosting</li>\n",
    "  </ul>\n",
    "  </div>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e3b784",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Setting The Scene\n",
    "\n",
    "<div style=\"display:flex; gap:20px;\">\n",
    "  <div style=\"flex:1;\">\n",
    "  <img src=\"media/images/bullet1.png\" alt=\"tab1\" scale=\"0.35;\" style=\"width: 20%;\">\n",
    "  <p>Most data that is interesting<br> enough for prediction has<br> some inherent structure.</p>\n",
    "  </div>\n",
    "  <div style=\"flex:1;\">\n",
    "  <img src=\"media/images/bullet2.png\" alt=\"tab1\" scale=\"0.35;\" style=\"width: 20%;\">\n",
    "  <p>Tree-based models exploit structure in data to split them into multiple homogenous subgroups</p>\n",
    "  <p>Approximates a (typically) discrete valued target function by repeatedly segmenting the predictor space into more homogeneous regions.</p>\n",
    "  <p>Represent a disjunction of conjunctions of constraints on the values of attributes representing the data.</p>\n",
    "  </div>\n",
    "  <div style=\"flex:1;\">\n",
    "  <img src=\"media/images/bullet3.png\" alt=\"tab1\" scale=\"0.35;\" style=\"width: 20%;\">\n",
    "  <p><b>Advantages</b></p>\n",
    "  <p>Training data need not be stored once the tree is constructed</p>\n",
    "  <p>Very fast during test time as test inputs only need to traverse down the tree to a leaf.</p>\n",
    "  <p>Decision trees require no distance metric because the splits are based on feature thresholds and not distances.</p>\n",
    "\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f279092",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decision Tree: Example\n",
    "\n",
    "- Assume a toy task that consisting of a dataset that contains several attributes related to trees growing in a plot of land. \n",
    "- Given only the $\\color{blue}{\\textbf{Diameter}}$ and $\\color{blue}{\\textbf{Height}}$ of a tree trunk, we must determine if it's an Apple, Cherry, or Oak tree. \n",
    "- To do this, we'll use a $\\color{blue}{\\textbf{Decision Tree}}$.\n",
    "\n",
    "<i>Let's start by investigating the data!</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "501d8175",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 150\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tree type</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cherry</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oak</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>Total</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tree type  Count\n",
       "0         apple     50\n",
       "1        cherry     50\n",
       "2           oak     50\n",
       "Total     Total    150"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[[\"Diameter\", \"Height\"]]\n",
    "print(\"Number of rows:\",len(data))\n",
    "\n",
    "#Number of instances per class\n",
    "class_counts = (\n",
    "    df[\"Family\"]\n",
    "    .value_counts()\n",
    "    .sort_index()\n",
    "    .rename_axis(\"Tree type\")\n",
    "    .reset_index(name=\"Count\")\n",
    ")\n",
    "\n",
    "class_counts.loc[\"Total\"] = [\"Total\", class_counts[\"Count\"].sum()]\n",
    "class_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd19fac6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"media/images/tree-data.png\" alt=\"Tree Data\" scale=\"0.55;\" style=\"width: 90%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78d245b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Decision Tree: Example\n",
    "\n",
    "Learned trees can also be thought of as <span style=\"color:blue;\"><i>sets of if-then rules</i></span> progressively dividing the feature space!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589a2377",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"media/gif/decision_tree_growth.gif\" alt=\"Decision Tree Example\" scale=\"0.55;\" style=\"width: 90%;\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
